{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88d68d7e7bc0c7344c243112e5877ad5",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Lab 3: CNNs and Deep Learning \n",
    "**(version 1.0)**\n",
    "\n",
    "### TBMI26/732A55 Neural Networks and Learning Systems 2020\n",
    "### Michael Felsberg\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Hint: Use the provided test cases to check if your solutions are valid.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2D Convolution\n",
    "It is widely used with 2D signals such as images. For the further steps, we often need to visualize an image and we define a shortcut for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def visualize(img, title=''):\n",
    "    plt.imshow(img,'gray')\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    print('Image size:', img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Task 1:** Convolution can be performed in 2D using the function `scipy.signal.convolove2d()`. Use this function to generate a 2D kernel of size $33\\times33$ by five times cascading 2D convolutions of $H$ with itself, starting with $H = \\begin{array}{|c|c|}\n",
    "      \\hline\n",
    "      1 & 1 \\\\\n",
    "      \\hline\n",
    "      1 & 1 \\\\\n",
    "      \\hline\n",
    "    \\end{array}/4$.   \n",
    "*Visualize* the kernel using `visualize` function defined above.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d43576cd6da3f4e75953d38569afccc9",
     "grade": false,
     "grade_id": "task1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "visualize(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5deae0a10b97eece51787b2c4037b34a",
     "grade": true,
     "grade_id": "task3t",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### TEST CELL. PLEASE DON'T CHANGE ###\n",
    "assert(H.sum().round()==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Task 2:** Now, load the image `'MR15^044.JPG'` (a sample from ImageNet), **sum** its RGB-channels, **normalize** it to the range [0,1], and convolve it with $H$ from task 3 under the options `'valid'` and `'same'`. \n",
    "\n",
    "What differences do you observe regarding the size of the output?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b16c9044f32ccabb6fcfd4b7e251a0ac",
     "grade": true,
     "grade_id": "task2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "visualize(img_gray, 'The normalized grayscale input image')      \n",
    "visualize(omg_sc_valid, 'The convolved image in \"valid\" mode')\n",
    "visualize(omg_sc_same, 'The convolved image in \"same\" mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2bbe089dc00bc5b5f17c847b7245f33",
     "grade": true,
     "grade_id": "task2t",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### TEST CELL. PLEASE DON'T CHANGE ###\n",
    "assert(img_gray.max() == 1.0)\n",
    "assert(omg_sc_valid.shape == (214, 216))\n",
    "assert(omg_sc_same.shape == (246, 248))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Strided convolution\n",
    "\n",
    "In strided convolution, samples are removed based on the stride. According to the Nyquist theorem, this can generate aliasing artifacts.  \n",
    "\n",
    "**Task 3:** Visualize the input image and the second output image from task 4, `omg_sc_same`, while only keping every *fifth* row and column. \n",
    "\n",
    "*Hint*: Use Python extended slicing, read this guid on [extended slices](https://docs.python.org/2.3/whatsnew/section-slices.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12074fe448972ac7d91f273811218c7c",
     "grade": true,
     "grade_id": "task3",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "visualize(img_gray_ds, 'Input image with stride of 5')\n",
    "visualize(omg_sc_same_ds, 'Filtered input image with stride of 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1bc9c449cdb5908d6bc267964c2cca7f",
     "grade": false,
     "grade_id": "cell-5427d9521d567b14",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "What do you observe, in particular at the ski?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "816b1ea80ce281b4d399085edd3b4718",
     "grade": true,
     "grade_id": "task3b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution in PyTorch\n",
    "PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing. It is primarily developed by Facebook's AI Research lab.\n",
    "\n",
    "We will start by utilizing PyTorch to perform convolution operations in 2D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Task 4:** Apply the cascaded $33\\times33$ filter from task 1 to the image using a `torch.nn.Conv2d` layer. \n",
    "\n",
    "Compare the results from *Scipy* in task 2 and *PyTorch* in this task by subtracting the output images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32f65294269482eb93a62dbfd56532c4",
     "grade": false,
     "grade_id": "task4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Hint: Convert the output tensor to numpy array\n",
    "visualize(out_2d_np, 'Filtered image using PyTorch') \n",
    "diff = np.abs(out_2d_np-omg_sc_same)\n",
    "visualize(diff, 'Diff. between Scipy and PyTorch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bd0626ecd9991a1ce5317f07d6a3a5c",
     "grade": true,
     "grade_id": "task4t",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### TEST CELL. PLEASE DON'T CHANGE ###\n",
    "assert(diff.mean()<1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Task 5:** Repeat the previous task with stride 5. Compare with `omg_sc_same_ds` from task 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9ad6239b300d4f19a95de16fc7a423c",
     "grade": false,
     "grade_id": "task5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Hint: Convert the output tensor to numpy array\n",
    "visualize(out_2d_s5_np, 'Filtered image using PyTorch with stride=5') \n",
    "diff_s5 = np.abs(out_2d_s5_np-omg_sc_same_ds)\n",
    "visualize(diff_s5, 'Diff. between Scipy and PyTorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d600321c36e06651763f6303591fbcbf",
     "grade": true,
     "grade_id": "task5t",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### TEST CELL. PLEASE DON'T CHANGE ###\n",
    "assert(diff_s5.mean()<1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Task 6:** Repeat task 5 with stride of 5 and a $1\\times1$ filter. Compare with `img_gray_ds` from task 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7893695a4b96fcaaa209996d19e6999e",
     "grade": false,
     "grade_id": "task6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Hint: Convert the output tensor to numpy array\n",
    "visualize(out_2d_s5_1_np, 'Filtered image using PyTorch with stride=5') \n",
    "diff_s5_1 = np.abs(out_2d_s5_1_np-img_gray_ds)\n",
    "visualize(diff_s5_1, 'Diff. between Scipy and PyTorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84f7d460c64d60209cd1258b66a54207",
     "grade": true,
     "grade_id": "task6t",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### TEST CELL. PLEASE DON'T CHANGE ###\n",
    "assert(diff_s5_1.mean()<1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training a PyTorch Convolution layer\n",
    "\n",
    "Now, we want the network to learn the convolution filter given the input and the filtered output.\n",
    "\n",
    "**Task 7:** Considering the input image tensor `inp_2d` from task 4 as a *batch* and the filtered output `out_2d_t` as a label, use `torch.optim.SGD` to learn the the filter $H$.\n",
    "\n",
    "**Hints**:\n",
    "- Use the L1 loss from `torch.nn.functional.l1_loss`.\n",
    "- Use a small learning rate.\n",
    "- Detach `out_2d_t` from the model graph in task 4 to avoid errors.\n",
    "- Iterate for 500 iterations.\n",
    "- Clip the weights after each iteration to $[0, \\infty[$ for stable convergence.\n",
    "- Print the loss every 100 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18bdf5952b977f61627b836bcdc9a94a",
     "grade": true,
     "grade_id": "task7",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the model and the optimizer\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Visualize the trained filter\n",
    "visualize(model_1layer.weight[0,0,:,:].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 8**:\n",
    "To make the transitiong to the next task easier, redo task 7 by defining a custom PyTorch module which includes only 1 convolution layer.  \n",
    "You can follow this [tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#define-the-network).  \n",
    "A custom module class inherits `torch.nn.Module` class and needs to have two mandatory functions:\n",
    "- `__init__(self):` where you define layers included in your module.\n",
    "- `forward(self, x):` where you define the inference steps of your network.\n",
    "\n",
    "The built-in auto-differentiation module in PyTorch will keep track of the operations that you perform in the inference steps and calculates their derivatives when you back-propagate the loss function during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4be3d3c2b921c11658bb654ba036f69b",
     "grade": true,
     "grade_id": "task8",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Visualize the trained filter\n",
    "visualize(net.conv1.weight[0,0,:,:].detach().cpu().numpy())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training a whole network\n",
    "So far, we have experimented with training a single convolution layer. Now we try to train a whole network to perform the task of image classification on CIFAR-10 dataset.  \n",
    "But first, make sure that CUDA is available by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 9:** We will train on CIFAR10, which is readily available at `torchvision.datasets.CIFAR10`. \n",
    "\n",
    "Create a dataloader for the *training* and the *test* sets of CIFAR10 using `torch.utils.data.DataLoader` , then show some examples from the training set using `torchvision.utils.make_grid` and print out their labels. \n",
    "\n",
    "*Hints* :\n",
    "- The `imshow` function for visualizing the images is provided below.\n",
    "- Use `torchvision.transforms` to perform whitening on images (normalization using the mean and the standard deviation).\n",
    "- Use a batch size of 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "acc6aca343a436e6f1a3893d8c4ebb23",
     "grade": true,
     "grade_id": "task9",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img * 0.2 + 0.5  # Un-Normalize, Change according to your normalization\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    return npimg.mean()\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Show some random images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "grid_img = torchvision.utils.make_grid(images)\n",
    "imshow(grid_img)\n",
    "\n",
    "# Print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fe9dfe09512a0a715d998df316fe548",
     "grade": true,
     "grade_id": "task9t",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### TEST CELL. PLEASE DON'T CHANGE ###\n",
    "assert(grid_img.std()>0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Baseline Model\n",
    "**Task 10:** Build the depicted LeNet5-inspired model using PyTorch standard components. Assume a **padding** with `same` mode for all convolution layers.   \n",
    "Try to figure out the missing dimension at the first fully connected layer.\n",
    "![architecture](arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e0094a69f2c7299857a643331a2686b",
     "grade": true,
     "grade_id": "task10",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        \n",
    "        # Define the network\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Perform Inference            \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = LeNet5().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Task 11:** Train the LeNet5 model for 40 epochs using a suitable batch size and display the result.\n",
    "\n",
    "*Hints*:\n",
    "- Define an optimizer, e.g. SGD optimizer.\n",
    "- Define a suitable loss function.\n",
    "- Iterate for 40 epochs and at each epoch calculate a running loss and accuracy on the training set.\n",
    "- After each epoch, evaluate the model on the test set. You can achieve this by **completing** the `test` function below that performs *only* inference on the test set and calculates the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1629bf225c024c2efe7108215559a64",
     "grade": true,
     "grade_id": "task11",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# A function to plot the accuracy training history\n",
    "def plot_model_history(history):\n",
    "    plt.figure(0)\n",
    "    plt.plot(history['train'],'r', lw=3)\n",
    "    plt.plot(history['test'],'b', lw=3)\n",
    "    plt.rcParams['figure.figsize'] = (8, 6)\n",
    "    plt.xlabel(\"Epoch number\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training Accuracy vs Test Accuracy\")\n",
    "    plt.legend(['Training','Test'])\n",
    "    plt.grid(True)\n",
    "\n",
    "# Test function that runs only inference\n",
    "def test(model, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    print('Test Accuracy: %d %%' % (100 * correct / total))\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce9eb25206ee6eaf35e335f057f86078",
     "grade": true,
     "grade_id": "task11b",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 40\n",
    "LR = 0.01\n",
    "\n",
    "# Define a proper optimizer and a proper loss function\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "acc_history = {'train':[], 'test':[]}\n",
    "\n",
    "# Iterate for N epochs\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print('Finished Training!')\n",
    "\n",
    "plot_model_history(acc_history)\n",
    "\n",
    "# Let's quickly save our trained model:\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## == MANDATORY QUESTIONS END HERE =="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Baseline + Decaying Learning Rate\n",
    "In most papers, the learning rate is successively reduced in order to boost the final performance, e.g. divided by two after 20 and 30 epochs.  \n",
    "**[EXTRA]**\n",
    "**Task 12:** Define a suitable function and train the previous model with decaying learning rate. Plot the result and compare it to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "341980cad9f8f20d59923d6a7d9ff0dc",
     "grade": true,
     "grade_id": "task12",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        lrate = param_group[\"lr\"]\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d14c7367935d4b5f01974f8472fcc238",
     "grade": true,
     "grade_id": "task12b",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "net_lr = LeNet5().to(device)\n",
    "\n",
    "# Define a proper optimizer and a proper loss function\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "acc_history_lr = {'train':[], 'test':[]}\n",
    "# Iterate for N epochs\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print('Finished Training!')\n",
    "\n",
    "plot_model_history(acc_history_lr)\n",
    "\n",
    "# Let's quickly save our trained model:\n",
    "PATH = './cifar_net_lr.pth'\n",
    "torch.save(net_lr.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Baseline +  Decaying Learning rate + Data Augmentation \n",
    "**[EXTRA]**\n",
    "**Task 13:** Data augmentation is known to reduce overfitting. Use `torchvision.transforms`to perform additional augmentation with flipping and random cropping. Adjust the number of epochs and the learning rate schedule if needed. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "423c9dde89cefa435413be72e68be12f",
     "grade": true,
     "grade_id": "task13",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68856c9fa2700f2e462c08042de1f3c3",
     "grade": true,
     "grade_id": "task13b",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "net_lr_wr_aug = LeNet5().to(device)\n",
    "\n",
    "# Define a proper optimizer and a proper loss function\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "acc_history_lr_wr_aug = {'train':[], 'test':[]}\n",
    "# Iterate for N epochs\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print('Finished Training!')\n",
    "\n",
    "plot_model_history(acc_history_lr_wr_aug)\n",
    "\n",
    "# Let's quickly save our trained model:\n",
    "PATH = './cifar_net_lr_wr_aug.pth'\n",
    "torch.save(net_lr_wr_aug.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
